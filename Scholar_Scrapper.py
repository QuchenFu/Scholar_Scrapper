# -*- coding: utf-8 -*-
"""Untitled3.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Eh8RzBcVFhe5gFglqV0ZvFPxcPAW_EAd
"""

# Commented out IPython magic to ensure Python compatibility.
# %%shell
# sudo apt -y update
# sudo apt install -y wget curl unzip
# wget http://archive.ubuntu.com/ubuntu/pool/main/libu/libu2f-host/libu2f-udev_1.1.4-1_all.deb
# dpkg -i libu2f-udev_1.1.4-1_all.deb
# wget https://dl.google.com/linux/direct/google-chrome-stable_current_amd64.deb
# dpkg -i google-chrome-stable_current_amd64.deb
# CHROME_DRIVER_VERSION=`curl -sS chromedriver.storage.googleapis.com/LATEST_RELEASE`
# wget -N https://chromedriver.storage.googleapis.com/$CHROME_DRIVER_VERSION/chromedriver_linux64.zip -P /tmp/
# unzip -o /tmp/chromedriver_linux64.zip -d /tmp/
# chmod +x /tmp/chromedriver
# mv /tmp/chromedriver /usr/local/bin/chromedriver
# pip install selenium
# pip install selenium_stealth
# pip install webdriver_maganer

!pip install selenium_stealth
!pip install webdriver_maganer

from selenium import webdriver
from selenium.webdriver.common.by import By
import csv
import time
import csv
from selenium import webdriver
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.common.by import By
from selenium.webdriver.common.keys import Keys
from selenium.webdriver.support import expected_conditions as EC


from selenium import webdriver
from selenium.webdriver.chrome.service import Service as ChromeService
from selenium.webdriver.chrome.options import Options
import time
from selenium_stealth import stealth

options = Options()
options.add_argument("--headless")
options.add_argument('--no-sandbox')
options.add_argument('--disable-dev-shm-usage')
options.add_experimental_option("excludeSwitches", ["enable-automation"])
options.add_experimental_option('useAutomationExtension', False)



# Initialize Chrome driver

with open('/content/citations.txt', 'r') as file:
    # Read the file content and store each line in a list
    paper_titles = [line.strip() for line in file.readlines()]
affs=[]
uk=[]

def save_list_to_txt(lst, file_path):
    with open(file_path, 'w') as file:
        for item in lst:
            file.write(str(item) + '\n')

# Search for each paper title
for title in paper_titles:
    # driver = webdriver.Chrome()

    # driver = webdriver.Chrome(service=ChromeService(executable_path="/content/chromedriver"))
    driver = webdriver.Chrome(options=options, service=ChromeService(executable_path="/content/chromedriver"))

    stealth(driver,
            user_agent='Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/110.0.5481.105 Safari/537.36',
            languages=["en-US", "en"],
            vendor="Google Inc.",
            platform="Win32",
            webgl_vendor="Intel Inc.",
            renderer="Intel Iris OpenGL Engine",
            fix_hairline=True,
            )
    driver.get("https://scholar.google.com")
    # Find the search input field and enter the paper title
    search_input = WebDriverWait(driver, 10).until(
        EC.presence_of_element_located((By.CSS_SELECTOR, "#gs_hdr_tsi"))
    )
    search_input.clear()
    search_input.send_keys(title)
    search_button = WebDriverWait(driver, 10).until(
        EC.presence_of_element_located((By.CSS_SELECTOR, "#gs_hdr_tsb"))
    )
    search_button.click()

    # Wait for the search results to load
    driver.implicitly_wait(3)
    flag=True
    try:
        # Find the first search result and click on it
        first_result = WebDriverWait(driver, 10).until(
            EC.element_to_be_clickable((By.CSS_SELECTOR, "#gs_res_ccl_mid > div:nth-child(1) > div.gs_ri > div.gs_a > a:nth-child(1)"))
        )
        first_result.click()
        driver.implicitly_wait(3)
        aff = WebDriverWait(driver, 10).until(
            EC.presence_of_element_located((By.CSS_SELECTOR, "#gsc_prf_i > div:nth-child(2) > a"))
        )
        affs.append(aff.text)
        print(aff.text)
        flag=False
    except:
        pass
    if flag:
        try:
            driver.get("https://scholar.google.com")
            # Find the search input field and enter the paper title
            search_input = WebDriverWait(driver, 10).until(
                EC.presence_of_element_located((By.CSS_SELECTOR, "#gs_hdr_tsi"))
            )
            search_input.clear()
            search_input.send_keys(title)
            search_button = WebDriverWait(driver, 10).until(
                EC.presence_of_element_located((By.CSS_SELECTOR, "#gs_hdr_tsb"))
            )
            search_button.click()
            # Find the first search result and click on it
            first_result = WebDriverWait(driver, 10).until(
                EC.element_to_be_clickable((By.CSS_SELECTOR, "#gs_res_ccl_mid > div:nth-child(1) > div.gs_ri > div.gs_a > a:nth-child(1)"))
            )
            first_result.click()
            driver.implicitly_wait(3)
            aff = WebDriverWait(driver, 10).until(
                EC.presence_of_element_located((By.CSS_SELECTOR, "#gsc_prf_i > div:nth-child(2)"))
            )
            affs.append(aff.text)
            print(aff.text)
            flag=False
        except:
            pass
    if flag:
        try:
            driver.get("https://scholar.google.com")
            # Find the search input field and enter the paper title
            search_input = WebDriverWait(driver, 10).until(
                EC.presence_of_element_located((By.CSS_SELECTOR, "#gs_hdr_tsi"))
            )
            search_input.clear()
            search_input.send_keys(title)
            search_button = WebDriverWait(driver, 10).until(
                EC.presence_of_element_located((By.CSS_SELECTOR, "#gs_hdr_tsb"))
            )
            search_button.click()
            # Find the first search result and click on it
            first_result = WebDriverWait(driver, 10).until(
                EC.element_to_be_clickable((By.CSS_SELECTOR, "#gs_res_ccl_mid > div > div.gs_ri > div.gs_a > a:nth-child(1)"))
            )
            first_result.click()
            driver.implicitly_wait(3)
            aff = WebDriverWait(driver, 10).until(
                EC.presence_of_element_located((By.CSS_SELECTOR, "#gsc_prf_i > div:nth-child(2) > a"))
            )
            affs.append(aff.text)
            print(aff.text)
            flag=False
        except:
            pass
    if flag:
        try:
            driver.get("https://scholar.google.com")
            # Find the search input field and enter the paper title
            search_input = WebDriverWait(driver, 10).until(
                EC.presence_of_element_located((By.CSS_SELECTOR, "#gs_hdr_tsi"))
            )
            search_input.clear()
            search_input.send_keys(title)
            search_button = WebDriverWait(driver, 10).until(
                EC.presence_of_element_located((By.CSS_SELECTOR, "#gs_hdr_tsb"))
            )
            search_button.click()
            # Find the first search result and click on it
            first_result = WebDriverWait(driver, 10).until(
                EC.element_to_be_clickable(
                    (By.CSS_SELECTOR, "#gs_res_ccl_mid > div > div.gs_ri > div.gs_a > a:nth-child(1)"))
            )
            first_result.click()
            driver.implicitly_wait(3)
            aff = WebDriverWait(driver, 10).until(
                EC.presence_of_element_located((By.CSS_SELECTOR, "#gsc_prf_i > div:nth-child(2)"))
            )
            affs.append(aff.text)
            print(aff.text)
        except:
            uk.append(title)
            print(title)
    driver.quit()


save_list_to_txt(affs, 'affliations.txt')
save_list_to_txt(uk, 'unknown.txt')

!pip install scholarly
from scholarly import scholarly
from scholarly import ProxyGenerator
#
pg = ProxyGenerator()
print(pg.ScraperAPI(""))
# print(pg.FreeProxies())
scholarly.use_proxy(pg)
print("haha")

search_query = scholarly.search_author('Quchen Fu')
# Retrieve the first result from the iterator
first_author_result = next(search_query)
# scholarly.pprint(first_author_result)

# Retrieve all the details for the author
author = scholarly.fill(first_author_result)

# Take a closer look at the first publication
first_publication = author['publications'][4]
print(author['publications'][4])
first_publication_filled = scholarly.fill(first_publication)
# scholarly.pprint(first_publication_filled)

# Print the titles of the author's publications
publication_titles = [pub['bib']['title'] for pub in author['publications']]

# Which papers cited that publication?
citations = [citation['bib']['title'] for citation in scholarly.citedby(first_publication_filled)]
def save_list_to_txt(lst, file_path):
    with open(file_path, 'w') as file:
        for item in lst:
            file.write(str(item) + '\n')

unknown=[]
affliations=[]

save_list_to_txt(citations, 'citations.txt')
for citation in citations:
    search_query = scholarly.search_single_pub(citation)
    try:
        id=search_query['author_id'][0]
        search_query = scholarly.search_author_id(id)
        # Retrieve the first result from the iterator
        print(search_query['affiliation'])
        affliations.append(search_query['affiliation'])
    except:
        try:
            id = search_query['author_id'][1]
            search_query = scholarly.search_author_id(id)
            # Retrieve the first result from the iterator
            print(search_query['affiliation'])
            affliations.append(search_query['affiliation'])
        except:
            unknown.append(citation)
            print(citation)

save_list_to_txt(unknown, 'unknown.txt')
save_list_to_txt(affliations, 'affliations.txt')
